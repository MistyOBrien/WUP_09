---
title: "Weight of Fish"
author: "Misty O'Brien"
date: "Spring 2021"
output: 
  html_document:
    number_sections: true
    toc: true
---


```{r include=FALSE,echo=FALSE}
require(tigerstats)
require(tidyverse)
require(car)
Allfish <- read.csv(file = "Fish.csv")
Allfish$Species <- as.factor(Allfish$Species)
levels(Allfish$Species)
```

```{r}
Perch <- subset(Allfish, Species == "Perch")
Perch <- select(Perch, -Species)
Bream <- subset(Allfish, Species == "Bream")
Bream <- select(Bream, -Species)
Smelt <- subset(Allfish, Species == "Smelt")
Smelt <- select (Smelt, -Species )
```



# Introduction

<!--In this section you explain what you are trying to show.  Where did the data come from?  What is the research or other question you are trying to answer?!-->

## Build the best regression model you can that predicts the weight of perch
## Using only two predictor variables  


# Perch

```{r}
library(leaps)
regsubsets.out <-
    regsubsets(Weight ~ .,
               data = Perch,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

summary.out <- summary(regsubsets.out)
as.data.frame(summary.out$outmat)
subsets(regsubsets.out,statistic="adjr2",legend="bottomright",main="Adjusted R^2")
```
  
From the plot above we see that the best regression model is height and width. The model of height and width are the adjusted $r^2$ of about 0.9400. 

## Which is best??  

```{r}
which.max(summary.out$adjr2)
```
```{r}
summary.out$which[2,]
```

```{r}
best.model <- lm(Weight~Height+Width ,data= Perch )
fullup<-lm(Weight~., data=Perch)
summary(best.model)
```

Here we get that the adjusted $r^2$ is 0.94 which is the best model because $r^2$ is the highest. The residual standard error is 85.17. The p-value is small here showing that the model is a good fit.


```{r}
anova(fullup,best.model)
```
The p-value is 0.879 showing that there is really no difference in using the model that has all of the variables vs the model that only has two variables

# Bream 

```{r}
library(leaps)
regsubsets.out <-
    regsubsets(Weight ~ .,
               data = Bream,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

summary.out <- summary(regsubsets.out)
as.data.frame(summary.out$outmat)
subsets(regsubsets.out,statistic="adjr2",legend="bottomright",main="Adjusted R^2")
```
  
From the plot above we see that the best regression model is Length1, width, and height . The model of height, width, and length1 are the adjusted $r^2$ of about 0.940. 

## Which is best??  

```{r}
which.max(summary.out$adjr2)
```
```{r}
summary.out$which[2,]
```

```{r}
best.model <- lm(Weight~Height+Width+Length1,data= Bream )
fullup<-lm(Weight~., data=Bream)
summary(best.model)
```

The adjusted $r^2$ of height, length1 and width is 0.9372. The residual standard error of the best regression models is 52.43. 

```{r}
anova(fullup,best.model)
```
The p-value is 0.8762. Since the p-value is large this shows that there is no difference between the best model which utilizes three variables and the best model which utilizes two variables.

# Smelt


```{r}
library(leaps)
regsubsets.out <-
    regsubsets(Weight ~ .,
               data = Smelt,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

summary.out <- summary(regsubsets.out)
as.data.frame(summary.out$outmat)
subsets(regsubsets.out,statistic="adjr2",legend="bottomright",main="Adjusted R^2")
```
  
From the plot above we see that the best regression model is Length1, Length2, width, and height. The model of height, width, and length1 are the adjusted $r^2$ of about 0.940. 

## Which is best??  

```{r}
which.max(summary.out$adjr2)
```
```{r}
summary.out$which[2,]
```

```{r}
best.model <- lm(Weight~Height+Width+Length1+Length2 ,data= Smelt )
fullup<-lm(Weight~.,data=Smelt)
summary(best.model)
```

The adjusted $r^2$ of height, length1, length2, and width is 0.9726. The residual standard error of the best regression model is 0.6842.

```{r}
anova(fullup,best.model)
```
The p-value is 0.6643. Since the p-value is slightly smalller here that means there is a significance difference between the best model which utilizes four variables and the best model which utilizes three variables. 

# Discussion and Conclusion

Based on automated selection of the variables there is no differences between using the model with two variables and the model with all the variables.This was identified through a graphical depiction of it the adjusted R- squared and the p-values. In conclusion comparing the P values of the two variable models vs the small P-values, we rejected the null hypothesis that these models are beneficial and predicting weight of fish. The P values associated with the anova were large and because of that we fail to  reject the null hypothesis. There is no real difference between using the model with two variables vs the full-up models.
